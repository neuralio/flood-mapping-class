# Flood Mapping in Central Luzon using Sentinel Data
# ðŸŒŠ Disaster Risk Reduction (DRR) Case Study

## 1. Introduction

This notebook demonstrates flood mapping in the Pampanga River Basin, Central Luzon, Philippines using free Sentinel satellite data. We'll analyze flood events from Typhoon Ulysses (2020) and Typhoon Karding (2022).

### Key Features:
- **Sentinel-1 SAR**: Cloud-penetrating radar imagery for flood detection
- **Sentinel-2 MSI**: Optical imagery for pre/post-event analysis
- **Methods**: Traditional thresholding and deep learning approaches

### Why Sentinel-1 for Flood Mapping?
Synthetic Aperture Radar (SAR) is ideal for flood detection because:
1. **All-weather capability**: Can penetrate clouds and rain
2. **Day/night operation**: Not dependent on sunlight
3. **Water sensitivity**: Water appears dark in SAR images due to specular reflection
4. **Regular revisit**: 6-12 day repeat cycle

---

## Setting Up the Environment

First, we'll import all necessary libraries. This notebook uses Google Earth Engine (GEE) for satellite data access, PyTorch for deep learning, and various Python libraries for data analysis and visualization.

```python
# Import required libraries
import ee
import geemap
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import folium
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
import rasterio
from rasterio.plot import show
import geopandas as gpd
from shapely.geometry import box
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import warnings
warnings.filterwarnings('ignore')

# Set plotting style
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
```

---

## 2. Initialize Google Earth Engine

Google Earth Engine requires authentication for first-time users. This cell will initialize the connection to GEE's cloud computing platform, which hosts petabytes of satellite imagery.

```python
# Initialize Earth Engine
try:
    ee.Initialize()
    print("Earth Engine initialized successfully!")
except:
    ee.Authenticate()
    ee.Initialize()
    print("Earth Engine authenticated and initialized!")
```

---

## 3. Define Study Area and Time Periods

Here we define our area of interest (AOI) - the Pampanga River Basin, which is frequently affected by flooding during typhoons. We also specify the dates for our two case study events.

The Pampanga River Basin:
- Covers approximately 10,540 kmÂ²
- Includes parts of Nueva Ecija, Pampanga, Bulacan, and Tarlac
- Home to over 6 million people
- Critical agricultural area (rice production)

```python
# Define the Pampanga River Basin boundary
pampanga_basin = ee.Geometry.Polygon([
    [120.4, 14.8],
    [121.2, 14.8],
    [121.2, 15.6],
    [120.4, 15.6],
    [120.4, 14.8]
])

# Define event dates
events = {
    'Typhoon Ulysses (Vamco)': {
        'pre_date': ['2020-11-01', '2020-11-10'],
        'post_date': ['2020-11-12', '2020-11-20'],
        'peak_date': '2020-11-11'
    },
    'Typhoon Karding (Noru)': {
        'pre_date': ['2022-09-15', '2022-09-24'],
        'post_date': ['2022-09-26', '2022-10-05'],
        'peak_date': '2022-09-25'
    }
}

# Visualization parameters
vis_params_s1 = {
    'min': -25,
    'max': 0,
    'palette': ['black', 'blue', 'cyan', 'yellow', 'red']
}

vis_params_flood = {
    'min': 0,
    'max': 1,
    'palette': ['white', 'blue']
}
```

---

## 4. Sentinel-1 SAR Data Acquisition and Preprocessing

Now we'll create functions to acquire and preprocess Sentinel-1 data. Sentinel-1 provides C-band SAR imagery with two polarizations:
- **VV (Vertical-Vertical)**: Good for general land/water discrimination
- **VH (Vertical-Horizontal)**: More sensitive to surface roughness, better for flood detection

### Key preprocessing steps:
1. **Speckle filtering**: Reduces noise inherent in SAR images
2. **dB conversion**: Converts to decibel scale for better visualization and analysis

```python
def get_sentinel1_data(aoi, start_date, end_date):
    """
    Acquire Sentinel-1 SAR data for the specified area and time period
    
    Parameters:
    - aoi: Area of Interest (ee.Geometry)
    - start_date: Start date string 'YYYY-MM-DD'
    - end_date: End date string 'YYYY-MM-DD'
    
    Returns:
    - ee.ImageCollection of Sentinel-1 images
    """
    s1_collection = (ee.ImageCollection('COPERNICUS/S1_GRD')
                    .filter(ee.Filter.eq('instrumentMode', 'IW'))
                    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))
                    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))
                    .filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING'))
                    .filterBounds(aoi)
                    .filterDate(start_date, end_date)
                    .select(['VH', 'VV']))
    
    return s1_collection

def preprocess_s1(image):
    """
    Preprocess Sentinel-1 images: apply speckle filter and convert to dB
    
    Speckle is a granular interference pattern in SAR images that degrades 
    image quality. We use a focal median filter to reduce this noise.
    """
    # Apply refined Lee speckle filter using focal median
    vh_filtered = image.select('VH').focal_median(radius=3, units='pixels')
    vv_filtered = image.select('VV').focal_median(radius=3, units='pixels')
    
    # Convert to dB scale: 10 * log10(DN)
    vh_db = ee.Image(10).multiply(vh_filtered.log10()).rename('VH_db')
    vv_db = ee.Image(10).multiply(vv_filtered.log10()).rename('VV_db')
    
    return image.addBands([vh_db, vv_db])
```

### Acquiring Pre and Post-Event Images

This cell processes both typhoon events, creating median composites of available images before and after each event. Using median composites helps reduce remaining noise and provides a representative view of the surface conditions.

```python
# Acquire data for both events
event_data = {}
for event_name, dates in events.items():
    print(f"Processing {event_name}...")
    
    # Get pre-event data (baseline conditions)
    pre_collection = get_sentinel1_data(pampanga_basin, 
                                       dates['pre_date'][0], 
                                       dates['pre_date'][1])
    pre_image = pre_collection.map(preprocess_s1).median().clip(pampanga_basin)
    
    # Get post-event data (flood conditions)
    post_collection = get_sentinel1_data(pampanga_basin, 
                                        dates['post_date'][0], 
                                        dates['post_date'][1])
    post_image = post_collection.map(preprocess_s1).median().clip(pampanga_basin)
    
    event_data[event_name] = {
        'pre': pre_image,
        'post': post_image
    }
    
    print(f"  Pre-event images: {pre_collection.size().getInfo()}")
    print(f"  Post-event images: {post_collection.size().getInfo()}")
```

---

## 5. Traditional Flood Detection: SAR Amplitude Thresholding

The simplest approach to flood detection uses the principle that water appears darker in SAR images. By comparing pre and post-event images, we can identify areas that became significantly darker (indicating flooding).

### How it works:
1. Calculate the difference between post and pre-event SAR backscatter
2. Apply a threshold (typically -3 dB) to identify significant decreases
3. Clean up the result to remove noise

```python
def detect_flood_threshold(pre_image, post_image, threshold=-3):
    """
    Detect floods using simple amplitude difference thresholding
    
    The threshold of -3 dB is empirically derived and means that areas 
    where backscatter decreased by more than 3 dB are classified as flooded.
    
    Parameters:
    - pre_image: Pre-event SAR image
    - post_image: Post-event SAR image  
    - threshold: dB threshold for flood detection (default: -3)
    
    Returns:
    - Binary flood mask (1 = flood, 0 = no flood)
    """
    # Calculate difference in VH polarization (more sensitive to water)
    diff = post_image.select('VH_db').subtract(pre_image.select('VH_db'))
    
    # Apply threshold - areas with decrease greater than threshold are flooded
    flood_mask = diff.lt(threshold)
    
    # Clean up small patches using morphological filtering
    flood_mask = flood_mask.focal_mode(radius=2, units='pixels')
    
    return flood_mask
```

### Apply Threshold-based Detection

Now we'll apply the threshold method to both typhoon events and calculate the flooded area in square kilometers.

```python
# Apply threshold-based detection
flood_masks_threshold = {}
for event_name, data in event_data.items():
    flood_mask = detect_flood_threshold(data['pre'], data['post'])
    flood_masks_threshold[event_name] = flood_mask
    
    # Calculate flooded area
    # multiply by pixelArea() to convert pixel count to actual area
    flood_area = flood_mask.multiply(ee.Image.pixelArea()).reduceRegion(
        reducer=ee.Reducer.sum(),
        geometry=pampanga_basin,
        scale=30,  # Sentinel-1 resolution
        maxPixels=1e10
    )
    
    area_km2 = ee.Number(flood_area.get('VH_db')).divide(1e6)
    print(f"{event_name} - Flooded area: {area_km2.getInfo():.2f} kmÂ²")
```

---

## 6. Advanced Flood Detection: Automatic Thresholding

Manual threshold selection can be subjective. Here we implement Otsu's method, which automatically finds the optimal threshold by maximizing the between-class variance in the image histogram.

### Advantages:
- Objective and reproducible
- Adapts to different image conditions
- No need for manual threshold tuning

```python
def otsu_threshold(histogram):
    """
    Calculate Otsu's threshold for automatic thresholding
    
    Otsu's method assumes the image contains two classes of pixels 
    (flooded and non-flooded) and calculates the optimum threshold 
    separating those two classes.
    """
    counts = ee.Array(ee.Dictionary(histogram).get('histogram'))
    means = ee.Array(ee.Dictionary(histogram).get('bucketMeans'))
    
    size = counts.reduce(ee.Reducer.sum(), [0])
    total = means.multiply(counts).reduce(ee.Reducer.sum(), [0])
    mean = total.divide(size)
    
    indices = ee.List.sequence(0, counts.length().subtract(1))
    
    def compute_wcv(i):
        # Calculate within-class variance for each possible threshold
        w1 = counts.slice(0, 0, i).reduce(ee.Reducer.sum(), [0])
        w2 = counts.slice(0, i).reduce(ee.Reducer.sum(), [0])
        
        m1 = means.slice(0, 0, i).multiply(counts.slice(0, 0, i)) \
            .reduce(ee.Reducer.sum(), [0]).divide(w1)
        m2 = means.slice(0, i).multiply(counts.slice(0, i)) \
            .reduce(ee.Reducer.sum(), [0]).divide(w2)
        
        wcv = w1.multiply(w2).multiply(m1.subtract(m2).pow(2))
        return ee.List([i, wcv])
    
    wcv_list = indices.map(compute_wcv)
    
    # Find maximum WCV (optimal threshold)
    max_wcv = ee.Dictionary(wcv_list.reduce(ee.Reducer.max(2)))
    return means.get([ee.Number(max_wcv.get('max')).int()])

def advanced_flood_detection(pre_image, post_image, aoi):
    """
    Advanced flood detection using automatic thresholding
    
    This method combines both VH and VV polarizations and uses 
    Otsu's method to automatically determine the threshold.
    """
    # Calculate normalized difference for both polarizations
    diff_vh = post_image.select('VH_db').subtract(pre_image.select('VH_db'))
    diff_vv = post_image.select('VV_db').subtract(pre_image.select('VV_db'))
    
    # Combine polarizations (average)
    diff_combined = diff_vh.add(diff_vv).divide(2)
    
    # Calculate histogram for Otsu thresholding
    histogram = diff_combined.reduceRegion(
        reducer=ee.Reducer.histogram(255, 2).combine(
            reducer2=ee.Reducer.mean(),
            sharedInputs=True
        ),
        geometry=aoi,
        scale=30,
        bestEffort=True
    )
    
    # Get optimal threshold using Otsu's method
    threshold = otsu_threshold(histogram.get(diff_combined.bandNames().get(0)))
    
    # Apply threshold
    flood_mask = diff_combined.lt(threshold)
    
    # Post-processing: remove isolated pixels and fill holes
    flood_mask = flood_mask.focal_mode(radius=3, units='pixels')
    flood_mask = flood_mask.mask(flood_mask)
    
    return flood_mask
```

### Apply Advanced Detection Method

Let's apply the advanced detection method to our typhoon events. This should provide more robust results than the simple threshold approach.

```python
# Apply advanced detection
flood_masks_advanced = {}
for event_name, data in event_data.items():
    flood_mask = advanced_flood_detection(data['pre'], data['post'], pampanga_basin)
    flood_masks_advanced[event_name] = flood_mask
    print(f"Advanced detection completed for {event_name}")
```

---

## 7. Sentinel-2 Optical Data for Validation

While SAR is excellent for flood detection, optical imagery from Sentinel-2 can provide validation when cloud-free conditions exist. We'll calculate water indices that highlight water bodies.

### Water Indices:
1. **NDWI**: Normalized Difference Water Index - uses green and NIR bands
2. **MNDWI**: Modified NDWI - uses green and SWIR, better for urban water bodies
3. **AWEI**: Automated Water Extraction Index - multi-band approach for improved accuracy

```python
def get_sentinel2_data(aoi, start_date, end_date):
    """
    Acquire Sentinel-2 optical data
    
    Note: We filter for images with less than 20% cloud cover,
    but post-typhoon conditions often have extensive cloud coverage.
    """
    s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR')
                    .filterBounds(aoi)
                    .filterDate(start_date, end_date)
                    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))
                    .select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12']))
    
    return s2_collection

def calculate_water_indices(image):
    """
    Calculate multiple water indices from Sentinel-2
    
    Each index exploits different spectral properties of water:
    - NDWI: Water has high reflectance in green, low in NIR
    - MNDWI: SWIR is strongly absorbed by water
    - AWEI: Combines multiple bands for robust water detection
    """
    # Normalized Difference Water Index (NDWI)
    # (Green - NIR) / (Green + NIR)
    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')
    
    # Modified NDWI (MNDWI) 
    # (Green - SWIR1) / (Green + SWIR1)
    mndwi = image.normalizedDifference(['B3', 'B11']).rename('MNDWI')
    
    # Automated Water Extraction Index (AWEI)
    # Complex formula that combines multiple bands
    awei = image.expression(
        '4 * (GREEN - SWIR1) - (0.25 * NIR + 2.75 * SWIR2)',
        {
            'GREEN': image.select('B3'),
            'SWIR1': image.select('B11'),
            'NIR': image.select('B8'),
            'SWIR2': image.select('B12')
        }
    ).rename('AWEI')
    
    return image.addBands([ndwi, mndwi, awei])
```

### Retrieve Sentinel-2 Data

Let's try to get cloud-free Sentinel-2 images after each typhoon event. Due to weather conditions, this may not always be possible.

```python
# Get Sentinel-2 data for validation
s2_data = {}
for event_name, dates in events.items():
    # Try to get cloud-free images in the post-event period
    post_s2 = get_sentinel2_data(pampanga_basin, 
                                dates['post_date'][0], 
                                dates['post_date'][1])
    
    if post_s2.size().getInfo() > 0:
        # Create median composite and calculate water indices
        s2_image = post_s2.map(calculate_water_indices).median().clip(pampanga_basin)
        s2_data[event_name] = s2_image
        print(f"{event_name}: Found {post_s2.size().getInfo()} Sentinel-2 images")
    else:
        print(f"{event_name}: No cloud-free Sentinel-2 images available")
```

---

## 8. Deep Learning Approach: U-Net for Flood Segmentation

For more accurate flood mapping, we can use deep learning. U-Net is a convolutional neural network architecture designed for image segmentation tasks. It's particularly effective for flood mapping because it can learn complex patterns in SAR imagery.

### U-Net Architecture:
- **Encoder path**: Captures context through successive convolutions and pooling
- **Decoder path**: Enables precise localization through upsampling
- **Skip connections**: Combine high-resolution features from encoder with upsampled features

```python
class UNet(nn.Module):
    """
    U-Net architecture for flood segmentation
    
    The network takes as input:
    - 2 channels: pre-event and post-event SAR images
    
    And outputs:
    - 1 channel: probability map of flood presence (0-1)
    """
    def __init__(self, in_channels, out_channels):
        super(UNet, self).__init__()
        
        # Encoder (downsampling path)
        self.enc1 = self.conv_block(in_channels, 64)
        self.enc2 = self.conv_block(64, 128)
        self.enc3 = self.conv_block(128, 256)
        self.enc4 = self.conv_block(256, 512)
        
        # Bottleneck
        self.bottleneck = self.conv_block(512, 1024)
        
        # Decoder (upsampling path)
        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.dec4 = self.conv_block(1024, 512)
        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.dec3 = self.conv_block(512, 256)
        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dec2 = self.conv_block(256, 128)
        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.dec1 = self.conv_block(128, 64)
        
        # Output layer
        self.out = nn.Conv2d(64, out_channels, kernel_size=1)
        
    def conv_block(self, in_channels, out_channels):
        """
        Basic convolutional block: Conv -> BatchNorm -> ReLU -> Conv -> BatchNorm -> ReLU
        """
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        # Encoder
        e1 = self.enc1(x)
        e2 = self.enc2(F.max_pool2d(e1, 2))
        e3 = self.enc3(F.max_pool2d(e2, 2))
        e4 = self.enc4(F.max_pool2d(e3, 2))
        
        # Bottleneck
        b = self.bottleneck(F.max_pool2d(e4, 2))
        
        # Decoder with skip connections
        d4 = self.dec4(torch.cat([self.upconv4(b), e4], dim=1))
        d3 = self.dec3(torch.cat([self.upconv3(d4), e3], dim=1))
        d2 = self.dec2(torch.cat([self.upconv2(d3), e2], dim=1))
        d1 = self.dec1(torch.cat([self.upconv1(d2), e1], dim=1))
        
        return torch.sigmoid(self.out(d1))
```

### Dataset Class for Training

To train the U-Net model, we need a custom dataset class that handles SAR image pairs and their corresponding flood masks.

```python
# Dataset class for SAR flood data
class FloodDataset(Dataset):
    """
    PyTorch dataset for flood detection
    
    This class would be used to load training data consisting of:
    - Pre-event SAR images
    - Post-event SAR images  
    - Ground truth flood masks (manually labeled or from other sources)
    """
    def __init__(self, pre_images, post_images, flood_masks, transform=None):
        self.pre_images = pre_images
        self.post_images = post_images
        self.flood_masks = flood_masks
        self.transform = transform
    
    def __len__(self):
        return len(self.pre_images)
    
    def __getitem__(self, idx):
        # Stack pre and post images as separate channels
        input_data = np.stack([
            self.pre_images[idx],
            self.post_images[idx]
        ], axis=0)
        
        mask = self.flood_masks[idx]
        
        if self.transform:
            input_data = self.transform(input_data)
            mask = self.transform(mask)
        
        return torch.FloatTensor(input_data), torch.FloatTensor(mask)
```

### Model Training Setup

This cell sets up the U-Net model for training. In practice, you would need labeled training data from previous flood events.

```python
# Training function (placeholder - requires actual training data)
def train_unet_model():
    """
    Train U-Net model for flood detection
    
    Note: This is a template. Actual implementation requires:
    - Downloaded and preprocessed training data
    - Ground truth flood masks (from field surveys or manual labeling)
    - Data augmentation (rotation, flipping, etc.)
    - GPU resources for efficient training
    
    Training process:
    1. Load pre/post SAR image pairs
    2. Load corresponding ground truth masks
    3. Train model to predict masks from image pairs
    4. Validate on held-out test set
    """
    # Model initialization
    model = UNet(in_channels=2, out_channels=1)
    criterion = nn.BCELoss()  # Binary cross-entropy for binary segmentation
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    
    print("U-Net model initialized with:")
    print(f"  Parameters: {sum(p.numel() for p in model.parameters()):,}")
    print("  Input: 2 channels (pre/post SAR)")
    print("  Output: 1 channel (flood probability)")
    
    # Training loop would go here
    # for epoch in range(num_epochs):
    #     for batch in dataloader:
    #         # Forward pass, loss calculation, backpropagation
    
    return model

# Initialize model (for demonstration)
model = train_unet_model()
```

---

## 9. Visualization and Mapping

Creating effective visualizations is crucial for communicating flood extent to decision-makers. We'll create interactive maps that overlay flood detection results on base maps.

### Interactive Map Features:
- Multiple base map options
- Toggleable layers for SAR imagery and flood masks
- Opacity controls for better visualization
- Zoom and pan capabilities

```python
# Create interactive map
def create_flood_map(event_name, flood_mask, base_image):
    """
    Create an interactive folium map with flood overlay
    
    This function creates a web-based map that can be shared with 
    stakeholders for decision-making during disaster response.
    """
    # Get center coordinates of the basin
    center = pampanga_basin.centroid().coordinates().getInfo()
    
    # Create folium map centered on Pampanga Basin
    m = folium.Map(location=[center[1], center[0]], zoom_start=9)
    
    # Add base layers
    folium.TileLayer('openstreetmap').add_to(m)
    folium.TileLayer('CartoDB dark_matter').add_to(m)
    
    # Add SAR image layer
    sar_layer = folium.raster_layers.ImageOverlay(
        name=f'SAR Post-{event_name}',
        image=base_image.select('VH_db').getThumbUrl({
            'min': -25,
            'max': 0,
            'palette': ['000000', '0000FF', '00FFFF', 'FFFF00', 'FF0000'],
            'dimensions': 512
        }),
        bounds=[[14.8, 120.4], [15.6, 121.2]],
        opacity=0.6
    )
    sar_layer.add_to(m)
    
    # Add flood mask layer
    flood_layer = folium.raster_layers.ImageOverlay(
        name=f'Flood Extent - {event_name}',
        image=flood_mask.getThumbUrl({
            'min': 0,
            'max': 1,
            'palette': ['ffffff', '0000ff'],
            'dimensions': 512
        }),
        bounds=[[14.8, 120.4], [15.6, 121.2]],
        opacity=0.7
    )
    flood_layer.add_to(m)
    
    # Add layer control
    folium.LayerControl().add_to(m)
    
    return m
```

### Generate Maps for Each Event

Now let's create interactive maps for both typhoon events showing the detected flood extents.

```python
# Create maps for each event
maps = {}
for event_name in events.keys():
    if event_name in flood_masks_advanced:
        maps[event_name] = create_flood_map(
            event_name,
            flood_masks_advanced[event_name],
            event_data[event_name]['post']
        )
        print(f"Interactive map created for {event_name}")

# Display map for Typhoon Ulysses
if 'Typhoon Ulysses (Vamco)' in maps:
    display(maps['Typhoon Ulysses (Vamco)'])
```

---

## 10. Statistical Analysis and Validation

Quantitative analysis of flood extent is essential for damage assessment and resource allocation. We'll calculate key statistics and create visualizations to compare the two typhoon events.

### Key Metrics:
- Total flooded area in kmÂ²
- Percentage of basin affected
- Number of affected pixels
- Comparison between events

```python
def analyze_flood_statistics(flood_mask, aoi, event_name):
    """
    Calculate comprehensive flood statistics
    
    These statistics are crucial for:
    - Damage assessment
    - Resource allocation
    - Insurance claims
    - Historical comparison
    """
    # Total flooded area
    flood_area = flood_mask.multiply(ee.Image.pixelArea()).reduceRegion(
        reducer=ee.Reducer.sum(),
        geometry=aoi,
        scale=30,
        maxPixels=1e10
    )
    
    # Flood pixel count
    flood_count = flood_mask.reduceRegion(
        reducer=ee.Reducer.sum(),
        geometry=aoi,
        scale=30,
        maxPixels=1e10
    )
    
    # Get statistics
    area_km2 = ee.Number(flood_area.values().get(0)).divide(1e6)
    pixel_count = flood_count.values().get(0)
    
    stats = {
        'event': event_name,
        'flooded_area_km2': area_km2.getInfo(),
        'flooded_pixels': pixel_count.getInfo(),
        'percentage': None  # To be calculated
    }
    
    # Calculate percentage of basin flooded
    basin_area = aoi.area().divide(1e6)
    stats['percentage'] = (area_km2.divide(basin_area).multiply(100)).getInfo()
    
    return stats
```

### Compute and Visualize Statistics

Let's calculate statistics for both events and create visualizations to compare their impacts.

```python
# Analyze all events
flood_statistics = []
for event_name in events.keys():
    if event_name in flood_masks_advanced:
        stats = analyze_flood_statistics(
            flood_masks_advanced[event_name],
            pampanga_basin,
            event_name
        )
        flood_statistics.append(stats)
        print(f"Statistics calculated for {event_name}")

# Create DataFrame for easy analysis
df_stats = pd.DataFrame(flood_statistics)
print("\nFlood Statistics Summary:")
print(df_stats)
print("\nKey Findings:")
print(f"- Total area analyzed: ~10,540 kmÂ² (Pampanga River Basin)")
print(f"- Spatial resolution: 30m (Sentinel-1 GRD)")
```

### Create Comparison Visualizations

Visual comparisons help stakeholders quickly understand the relative impacts of different flood events.

```python
# Visualization
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Bar plot of flooded areas
ax1.bar(df_stats['event'], df_stats['flooded_area_km2'], color=['#1f77b4', '#ff7f0e'])
ax1.set_xlabel('Typhoon Event')
ax1.set_ylabel('Flooded Area (kmÂ²)')
ax1.set_title('Flood Extent Comparison')
ax1.tick_params(axis='x', rotation=15)

# Add value labels on bars
for i, v in enumerate(df_stats['flooded_area_km2']):
    ax1.text(i, v + 10, f'{v:.1f} kmÂ²', ha='center')

# Pie chart of flood percentage
ax2.pie(df_stats['percentage'], labels=df_stats['event'], autopct='%1.1f%%', 
        colors=['#1f77b4', '#ff7f0e'], startangle=90)
ax2.set_title('Percentage of Basin Flooded')

plt.tight_layout()
plt.show()
```

---

## 11. Export Results

For integration with GIS systems and further analysis, we need to export our flood detection results. Google Earth Engine allows exports to Google Drive or Earth Engine Assets.

### Export Options:
- **Format**: GeoTIFF (compatible with all GIS software)
- **Resolution**: 30m (native Sentinel-1 resolution)
- **Projection**: WGS84 (EPSG:4326)

```python
def export_flood_products(flood_mask, event_name, scale=30):
    """
    Export flood detection results
    
    Exported files can be used in:
    - QGIS/ArcGIS for further analysis
    - Web mapping applications
    - Report generation
    - Historical flood database
    """
    # Define export parameters
    export_params = {
        'image': flood_mask,
        'description': f'flood_mask_{event_name.replace(" ", "_")}',
        'folder': 'flood_mapping_central_luzon',
        'scale': scale,
        'region': pampanga_basin,
        'maxPixels': 1e10,
        'crs': 'EPSG:4326'
    }
    
    # Export to Drive
    task = ee.batch.Export.image.toDrive(**export_params)
    task.start()
    
    print(f"Export started for {event_name}")
    print(f"Task ID: {task.status()['id']}")
    print(f"File will be saved to: Google Drive/flood_mapping_central_luzon/")
    
    return task
```

### Start Export Tasks

Execute the exports for both flood events. The files will appear in your Google Drive once processing is complete.

```python
# Export flood masks
export_tasks = []
for event_name, flood_mask in flood_masks_advanced.items():
    task = export_flood_products(flood_mask, event_name)
    export_tasks.append(task)

print("\nMonitor export progress at:")
print("https://code.earthengine.google.com/tasks")
print("\nExported files will include:")
print("- Binary flood masks (0 = no flood, 1 = flood)")
print("- Georeferenced GeoTIFF format")
print("- Ready for use in GIS software")
```

---

## 12. Integration with Historical Hazard Maps

For effective disaster risk reduction, it's important to compare our flood detection results with existing hazard maps. This helps validate our results and identify areas where flood risk may be changing.

### Data Sources for Hazard Maps:
- **Project NOAH**: Nationwide Operational Assessment of Hazards
- **DOST-PAGASA**: Official weather bureau hazard maps
- **LGU Maps**: Local government unit flood hazard assessments
- **DREAM/Phil-LiDAR**: High-resolution elevation-based flood models

```python
# Load historical hazard maps (if available)
def compare_with_hazard_maps(flood_mask, hazard_map_asset):
    """
    Compare detected floods with historical hazard maps
    
    This comparison helps:
    - Validate detection accuracy
    - Identify changing flood patterns
    - Update hazard maps with recent events
    - Improve flood risk models
    """
    # Load hazard map from Earth Engine Asset
    # hazard_map = ee.Image(hazard_map_asset)
    
    # For demonstration, create a mock hazard map
    # In practice, you would load actual hazard maps from:
    # - Project NOAH (https://noah.up.edu.ph)
    # - DOST-PAGASA
    # - Local government hazard maps
    
    print("Hazard map comparison workflow:")
    print("1. Load historical flood hazard maps")
    print("2. Reclassify hazard levels (Low, Medium, High)")
    print("3. Compare with detected flood extent")
    print("4. Calculate accuracy metrics:")
    print("   - True Positives: Correctly detected floods in high-risk areas")
    print("   - False Positives: Detected floods in low-risk areas")
    print("   - False Negatives: Missed floods in high-risk areas")
    print("5. Identify areas of over/under-estimation")
    
    # Placeholder for actual comparison
    # overlap = flood_mask.multiply(hazard_map)
    # accuracy = overlap.reduceRegion(...)
    
    return None
```

### Recommendations for Operational Use

Based on this case study, here are recommendations for implementing an operational flood monitoring system.

```python
# Recommendations for operational use
print("\n" + "="*50)
print("RECOMMENDATIONS FOR OPERATIONAL DEPLOYMENT")
print("="*50)
print("\n1. DATA ACQUISITION:")
print("   - Set up automated Sentinel-1 data ingestion")
print("   - Monitor data availability (6-12 day revisit)")
print("   - Implement cloud-based processing pipeline")
print("   - Consider multiple satellite sources (ALOS-2, TerraSAR-X)")

print("\n2. PROCESSING WORKFLOW:")
print("   - Use Google Earth Engine for large-scale processing")
print("   - Implement near-real-time flood detection (within 6 hours)")
print("   - Validate with ground truth data when available")
print("   - Maintain processing logs for quality assurance")

print("\n3. INTEGRATION:")
print("   - Connect with early warning systems")
print("   - Feed into disaster response protocols")
print("   - Archive results for historical analysis")
print("   - Share with relevant agencies (NDRRMC, LGUs)")

print("\n4. VALIDATION:")
print("   - Cross-validate with Sentinel-2 when cloud-free")
print("   - Compare with field reports and drone surveys")
print("   - Continuously improve thresholds based on feedback")
print("   - Maintain accuracy metrics database")

print("\n5. DISSEMINATION:")
print("   - Create web dashboard for stakeholders")
print("   - Generate automated reports (PDF/HTML)")
print("   - Provide data to local government units")
print("   - SMS/email alerts for critical areas")
```

---

## 13. Future Improvements

This section outlines potential enhancements to make the flood mapping system more robust and comprehensive.

```python
print("\n" + "="*50)
print("SUGGESTED ENHANCEMENTS")
print("="*50)

improvements = [
    {
        "Enhancement": "Multi-temporal Analysis",
        "Description": "Use time-series of SAR data to improve flood detection accuracy",
        "Implementation": "Stack multiple pre/post images, apply temporal filters"
    },
    {
        "Enhancement": "Machine Learning Pipeline",
        "Description": "Train deep learning models on local flood events",
        "Implementation": "Collect ground truth data, implement transfer learning"
    },
    {
        "Enhancement": "Multi-sensor Fusion",
        "Description": "Combine Sentinel-1, Sentinel-2, and Sentinel-3 data",
        "Implementation": "Develop fusion algorithms for comprehensive monitoring"
    },
    {
        "Enhancement": "Damage Assessment",
        "Description": "Estimate flood impact on infrastructure and agriculture",
        "Implementation": "Integrate land use maps, calculate affected areas by category"
    },
    {
        "Enhancement": "Real-time Dashboard",
        "Description": "Web-based platform for flood monitoring",
        "Implementation": "Use Flask/Django backend with Leaflet frontend"
    }
]

df_improvements = pd.DataFrame(improvements)
print(df_improvements.to_string(index=False))

print("\n" + "="*50)
print("CONCLUSION")
print("="*50)
print("\nThis notebook demonstrates a complete workflow for flood mapping")
print("in Central Luzon using free Sentinel satellite data. The methods")
print("shown can be adapted for other regions in the Philippines and")
print("integrated into operational disaster risk reduction systems.")
print("\nKey outputs:")
print("- Automated flood detection from SAR data")
print("- Quantitative flood extent measurements")
print("- Visualization tools for decision makers")
print("- Framework for operational deployment")
print("\nNext steps:")
print("1. Test on additional typhoon events")
print("2. Validate with field data")
print("3. Deploy as automated service")
print("4. Train local operators")
```